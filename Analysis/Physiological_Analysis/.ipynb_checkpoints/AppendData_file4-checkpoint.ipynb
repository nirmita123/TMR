{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Used to combine multiple empatica sessions corresponding to one study session - file 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of files to append: 2\n",
      "Subject ID: 28\n",
      "file 0 : 28_scent\n",
      "file 1 : 28_scent_r\n",
      "Successfully created the directory /Users/nirmita/Desktop/Data_Analysis/Reminessence_Physiological_Ananlysis/Data/Samples/study_part2/SleepData/28_scent1 \n"
     ]
    }
   ],
   "source": [
    "# chop off the noise before appending as timeline is going to fuck up\n",
    "# append all files \n",
    "# Things to remember: append from [2:end] timestamps will shift\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.io.common import EmptyDataError\n",
    "import os\n",
    "\n",
    "\n",
    "base=\"../../Reminessence_Physiological_Ananlysis/Data/Samples/study_part2/SleepData/\"\n",
    "\n",
    "n=input(\"No. of files to append: \")\n",
    "Dates=[]\n",
    "\n",
    "sID=input(\"Subject ID: \")\n",
    "condition=\"_scent1\"\n",
    "\n",
    "ibit=''\n",
    "IBI1=[]\n",
    "IBI2=[]\n",
    "BVP=[]\n",
    "EDA=[]\n",
    "te=[]\n",
    "HR=[]\n",
    "thr=[]\n",
    "HRV=[]\n",
    "thrv=[]\n",
    "Tags=[]\n",
    "\n",
    "for i in range(int(n)):\n",
    "    date=input(\"file \"+str(i)+\" : \")\n",
    "    dI=pd.read_csv(base+date+\"/IBI.csv\", header=None)\n",
    "    ibit=dI[0][0]\n",
    "    for j in range(1,len(dI)):\n",
    "        IBI1.append(dI[0][j])\n",
    "    for j in range(1,len(dI)):\n",
    "        IBI2.append(dI[1][j])\n",
    "    dB=pd.read_csv(base+date+\"/BVP.csv\", header=None)\n",
    "    if (i==0):\n",
    "        BVP.append(dB[0][0])\n",
    "    for j in range(1,len(dB)):\n",
    "        BVP.append(dB[0][j])\n",
    "    dE=pd.read_csv(base+date+\"/EDA.csv\")\n",
    "    for j in range(2,len(dE)):\n",
    "        EDA.append(dE['EDA'][j])\n",
    "        te.append(dE['Timestamp'][j])\n",
    "    dHR=pd.read_csv(base+date+\"/HR.csv\")\n",
    "    for j in range(2,len(dHR)):\n",
    "        HR.append(dHR['HR'][j])\n",
    "        thr.append(dHR['Timestamp'][j])\n",
    "    dHRV=pd.read_csv(base+date+\"/HRV.csv\")\n",
    "    for j in range(2,len(dHRV)):\n",
    "        HRV.append(dHRV['HRV'][j])\n",
    "        thrv.append(dHRV['Timestamp'][j])\n",
    "    try:\n",
    "        dt= pd.read_csv(base+date+'/tags.csv', header=None)\n",
    "    except EmptyDataError:\n",
    "        dt =pd.DataFrame()    \n",
    "    for j in range(len(dt)):\n",
    "        Tags.append(dt[0][j])\n",
    "        \n",
    "dfB=pd.DataFrame(BVP)\n",
    "dfI=pd.DataFrame({ibit: IBI1, 'IBI': IBI2})\n",
    "dfE=pd.DataFrame({'Timestamp': te, 'EDA': EDA})\n",
    "dfHR=pd.DataFrame({'Timestamp': thr, 'HR': HR})\n",
    "dfHRV=pd.DataFrame({'Timestamp': thrv, 'HRV':HRV})\n",
    "dft=pd.DataFrame(Tags)\n",
    "\n",
    "# define the name of the directory to be created\n",
    "path = base+sID+condition\n",
    "\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed\" % path)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \" % path)\n",
    "\n",
    "# save to csv in a new subject ID wise folder\n",
    "dfB.to_csv(base+sID+condition+\"/BVP.csv\", index=False)\n",
    "dfE.to_csv(base+sID+condition+\"/EDA.csv\", index=False)\n",
    "dfHR.to_csv(base+sID+condition+\"/HR.csv\", index=False)\n",
    "dfHRV.to_csv(base+sID+condition+\"/HRV.csv\", index=False)\n",
    "dft.to_csv(base+sID+condition+\"/tags.csv\", index=False)\n",
    "\n",
    "# Awake\n",
    "# Date=[\"2_703303_A01321_1\",\"2_703298_A01321_2\",\"3_726993_A00E51\",\"4_703483_A01321\",\"5_704274_A01321\",\"6_727024_A00E51\",\"7_705045_A01321\",\"8_727028_A00E51\",\"9_727030_A00E51\",\"11_705833_A01321\",\"13_706721_A01321\",\"14_736764_A01321\",\"15_727042_A00E51\",\"16_707151_A01321_1\",\"16_707157_A01321_2\"]\n",
    "# Sleep\n",
    "# Date=[\"1_697875_A01321\",\"2_698287_A01321_1\",\"2_703135_A01321_2\",\"2_698411_A01321_3\",\"3_698981_A01321\",\"4_699194_A00E51\",\"5_699469_A01321_1\",\"5_699861_A01321_2\",\"6_702300_A00E51\",\"7_701296_A01321_1\",\"7_701297_A01321_2\",\"11_701582_A01321_1\",\"11_701799_A01321_2\",\"13_702209_A01321_1\",\"13_702211_A01321_2\",\"14_703309_A01321_1\",\"14_702431_A01321_2\",\"16_702874_A00E51_1\",\"16_702986_A00E51_2\"]\n",
    "\n",
    "# Date=[\"2_703317_A01321\",\"3_727025_A00E51\",\"4_704261_A01321\",\"5_704830_A01321_1\",\"5_704912_A01321_2\",\"6_727029_A00E51_1\",\"6_727026_A00E51_2\",\"7_705820_A01321_1\",\"7_705821_A01321_2\",\"9_705821_A00E51_1\",\"9_727033_A00E51_2\",\"11_705921_A01321_1\",\"11_706139_A01321_2\",\"11_706157_A01321_3\",\"13_707098_A01321_1\",\"13_707099_A01321_2\",\"14_736770_A01321\",\"15_727041_A00E51_1\",\"15_727047_A00E51_2\",\"15_727043_A00E51_3\"]\n",
    "# Date=[\"2_c\",\"2_s\",\"3_c\",\"3_s\",\"4_c\",\"4_s\",\"5_c\",\"5_s\",\"6_c\",\"6_s\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find mean of every data sample\n",
    "import statistics as st\n",
    "\n",
    "\n",
    "base=\"/Users/nirmita/Desktop/Lotuscent/Samples/SleepData/\"\n",
    "\n",
    "Date=[\"1_c\",\"2_c\",\"3_c\",\"4_c\",\"5_c\",\"6_c\",\"9_c\",\"2_s\",\"3_s\",\"4_s\",\"5_s\",\"6_s\",\"7_s\",\"13_s\",\"14_s\",\"15_s\",\"16_s\"]\n",
    "\n",
    "EDA={}\n",
    "HRV={}\n",
    "HR={}\n",
    "for i in range(len(Date)):\n",
    "    date=Date[i]\n",
    "    d= pd.read_csv(base+date+\"/EDA.csv\")\n",
    "    d1= pd.read_csv(base+date+\"/HR.csv\")\n",
    "    d2= pd.read_csv(base+date+\"/HRV.csv\")\n",
    "    \n",
    "    HRV.update({date : st.mean(d2['HRV'])})\n",
    "    EDA.update({date : st.mean(d['EDA'])})\n",
    "    HR.update({date : st.mean(d1['HR'])})\n",
    "\n",
    "print(EDA)\n",
    "print(HRV)\n",
    "print(HR)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of files to append: 2\n",
      "Subject ID: 6\n",
      "file 0 : 6_s\n",
      "file 1 : 6_s_r\n",
      "Successfully created the directory ../Reminessence_Physiological_Ananlysis/Data/Samples/SleepData/6s \n"
     ]
    }
   ],
   "source": [
    "# chop off the noise before appending as timeline is going to fuck up\n",
    "# append all files \n",
    "# Things to remember: append from [2:end] timestamps will shift\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.io.common import EmptyDataError\n",
    "import os\n",
    "\n",
    "\n",
    "baseAwake=\"../Reminessence_Physiological_Ananlysis/Data/Samples/AwakeData/\"\n",
    "baseSleep=\"../Reminessence_Physiological_Ananlysis/Data/Samples/SleepData/\"\n",
    "\n",
    "base=baseSleep #change it to baseSleep for sleep data\n",
    "\n",
    "\n",
    "n=input(\"No. of files to append: \")\n",
    "Dates=[]\n",
    "\n",
    "sID=input(\"Subject ID: \")\n",
    "condition=\"s\"\n",
    "\n",
    "def add_data(file,st,data,time):\n",
    "    d=pd.read_csv(base+date+\"/\"+file+\".csv\")\n",
    "    \n",
    "    for j in range(2,len(d)):\n",
    "        data.append(d[st][j])\n",
    "        time.append(d['Timestamp'][j])\n",
    "    \n",
    "    return data,time\n",
    "    \n",
    "    \n",
    "ibit=''\n",
    "IBI1=[]\n",
    "IBI2=[]\n",
    "BVP=[]\n",
    "\n",
    "EDA=[]\n",
    "te=[]\n",
    "HR=[]\n",
    "thr=[]\n",
    "HRV=[]\n",
    "thrv=[]\n",
    "\n",
    "EDA_recall=[]\n",
    "te_recall=[]\n",
    "HR_recall=[]\n",
    "thr_recall=[]\n",
    "HRV_recall=[]\n",
    "thrv_recall=[]\n",
    "\n",
    "Tags=[]\n",
    "\n",
    "for i in range(int(n)):\n",
    "    date=input(\"file \"+str(i)+\" : \")\n",
    "    dI=pd.read_csv(base+date+\"/IBI.csv\", header=None)\n",
    "    ibit=dI[0][0]\n",
    "    for j in range(1,len(dI)):\n",
    "        IBI1.append(dI[0][j])\n",
    "    for j in range(1,len(dI)):\n",
    "        IBI2.append(dI[1][j])\n",
    "    dB=pd.read_csv(base+date+\"/BVP.csv\", header=None)\n",
    "    if (i==0):\n",
    "        BVP.append(dB[0][0])\n",
    "    for j in range(1,len(dB)):\n",
    "        BVP.append(dB[0][j])\n",
    "    \n",
    "    EDA,te=add_data('EDA_main','EDA',EDA,te)\n",
    "    HR,thr=add_data('HR_main','HR',HR,thr)\n",
    "    HRV,thrv=add_data('HRV_main','HRV',HRV,thrv)\n",
    "    \n",
    "    EDA_recall,te_recall=add_data('EDA_recall_main','EDA',EDA_recall,te_recall)\n",
    "    HR_recall,thr_recall=add_data('HR_recall_main','HR',HR_recall,thr_recall)\n",
    "    HRV_recall,thrv_recall=add_data('HRV_recall_main','HRV',HRV_recall,thrv_recall)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        dt= pd.read_csv(base+date+'/tags.csv', header=None)\n",
    "    except EmptyDataError:\n",
    "        dt =pd.DataFrame()    \n",
    "    for j in range(len(dt)):\n",
    "        Tags.append(dt[0][j])\n",
    "        \n",
    "dfB=pd.DataFrame(BVP)\n",
    "dfI=pd.DataFrame({ibit: IBI1, 'IBI': IBI2})\n",
    "dfE=pd.DataFrame({'Timestamp': te, 'EDA': EDA})\n",
    "dfHR=pd.DataFrame({'Timestamp': thr, 'HR': HR})\n",
    "dfHRV=pd.DataFrame({'Timestamp': thrv, 'HRV':HRV})\n",
    "dfE_recall=pd.DataFrame({'Timestamp': te_recall, 'EDA': EDA_recall})\n",
    "dfHR_recall=pd.DataFrame({'Timestamp': thr_recall, 'HR': HR_recall})\n",
    "dfHRV_recall=pd.DataFrame({'Timestamp': thrv_recall, 'HRV':HRV_recall})\n",
    "dft=pd.DataFrame(Tags)\n",
    "\n",
    "# define the name of the directory to be created\n",
    "path = base+sID+condition\n",
    "\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed\" % path)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \" % path)\n",
    "\n",
    "# save to csv in a new subject ID wise folder\n",
    "dfB.to_csv(base+sID+condition+\"/BVP.csv\", index=False)\n",
    "dfE.to_csv(base+sID+condition+\"/EDA.csv\", index=False)\n",
    "dfHR.to_csv(base+sID+condition+\"/HR.csv\", index=False)\n",
    "dfHRV.to_csv(base+sID+condition+\"/HRV.csv\", index=False)\n",
    "dfE_recall.to_csv(base+sID+condition+\"/EDA_recall.csv\", index=False)\n",
    "dfHR_recall.to_csv(base+sID+condition+\"/HR_recall.csv\", index=False)\n",
    "dfHRV_recall.to_csv(base+sID+condition+\"/HRV_recall.csv\", index=False)\n",
    "dft.to_csv(base+sID+condition+\"/tags.csv\", index=False)\n",
    "\n",
    "# Awake\n",
    "# Sleep\n",
    "# Date=[\"2_c_1\",\"2_c_2\",\"2_c_r\",\"2_s\",\"3_c\",\"3_s\",\"4_c\",\"4_s\",\"5_c\",\"5_s\",\"5_s_r\",\"6_c\",\"6_s\",\"6_s_r\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
